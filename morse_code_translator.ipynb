{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import keyboard\n",
    "import morse_code  # This module should handle Morse code translation\n",
    "import constants  # This module should define constants like EYE_AR_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye Aspect Ratio (EAR)\n",
    "\n",
    "The Eye Aspect Ratio (EAR) measures how the shape of the eye changes over time. It is useful for determining whether the eye is open or closed, which is important for applications such as detecting blinks or monitoring eye movement.\n",
    "\n",
    "#### Formula\n",
    "The formula for EAR is:\n",
    "\n",
    "EAR = (A + B) / 2 x C\n",
    "\n",
    "Where:\n",
    "- **A** is the distance between the top and bottom vertical eye landmarks.\n",
    "- **B** is the distance between the top and bottom vertical eye landmarks on the other side.\n",
    "- **C** is the distance between the horizontal eye landmarks (the width of the eye).\n",
    "\n",
    "#### Interpretation\n",
    "- **EAR > Threshold**: The eye is considered open.\n",
    "- **EAR < Threshold**: The eye is considered closed.\n",
    "\n",
    "The threshold value is empirically determined and can vary based on individual characteristics. It is used to decide whether the eye is in an open or closed state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection and Eye Landmark Tracking Setup\n",
    "\n",
    "This function sets up the tools and models needed to detect faces and track eye movements in real-time video.\n",
    "\n",
    "1. **Load Face Detector and Landmark Predictor**:\n",
    "   - It loads a pre-trained model to detect faces in video frames.\n",
    "   - It also loads another model to find specific facial landmarks (points) around the eyes.\n",
    "\n",
    "2. **Identify Eye Landmarks**:\n",
    "   - It gets the indices (positions) of the facial landmarks specifically for the left and right eyes.\n",
    "\n",
    "3. **Start Video Stream**:\n",
    "   - It opens the webcam (or other video source) to start capturing live video frames.\n",
    "\n",
    "4. **Return Setup Details**:\n",
    "   - It returns everything needed for processing the video: the video stream object, face detector, landmark predictor, and the eye landmark indices.\n",
    "\n",
    "#### Summary\n",
    "In summary, this function sets up the tools and models required to detect faces and track eye movements in real-time video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_detector_video(args):\n",
    "    print(\"[INFO] loading facial landmark predictor...\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "    print(\"[INFO] starting video stream thread...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    return vs, detector, predictor, lStart, lEnd, rStart, rEnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Morse Code Detection Using Eye Movements\n",
    "\n",
    "This function performs real-time Morse code detection based on eye movements. Hereâ€™s a step-by-step overview of how it works:\n",
    "\n",
    "1. **Initialize Counters and Flags**:\n",
    "   - Sets up counters and flags to keep track of eye movements and Morse code timing.\n",
    "\n",
    "2. **Capture Video Frames**:\n",
    "   - Continuously captures frames from the camera.\n",
    "\n",
    "3. **Detect Faces and Eyes**:\n",
    "   - For each frame, detects faces and identifies the position of the eyes.\n",
    "\n",
    "4. **Calculate Eye Aspect Ratio**:\n",
    "   - Measures how closed the eyes are by calculating the distance between key points around the eyes.\n",
    "\n",
    "5. **Draw Eye Contours**:\n",
    "   - Highlights the eyes in the video feed for better visualization.\n",
    "\n",
    "6. **Check Eye Status**:\n",
    "   - If the eyes are closed for a certain amount of time, interprets this as a Morse code dot or dash.\n",
    "   - If the eyes are open for a while, handles the separation between dots and dashes, or words.\n",
    "\n",
    "7. **Update Morse Code**:\n",
    "   - Updates and displays the current Morse code based on the eye movements.\n",
    "\n",
    "8. **Display Information**:\n",
    "   - Shows the current eye aspect ratio and Morse code on the screen.\n",
    "\n",
    "9. **Handle User Input**:\n",
    "   - Checks if a specific key is pressed to exit the program.\n",
    "\n",
    "10. **Return Results**:\n",
    "    - Returns the complete Morse code that was detected.\n",
    "\n",
    "#### Summary\n",
    "This process captures video frames, detects and analyzes eye movements to decode Morse code, and displays the results in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_camera(vs, detector, predictor, lStart, lEnd, rStart, rEnd):\n",
    "    # Initialize counters and flags\n",
    "    COUNTER = 0               # Counts consecutive frames where eyes are closed\n",
    "    BREAK_COUNTER = 0         # Counts frames where eyes are open to determine break periods\n",
    "    EYES_OPEN_COUNTER = 0     # Counts consecutive frames where eyes are open\n",
    "    CLOSED_EYES = False       # Flag to indicate if eyes are considered closed\n",
    "    WORD_PAUSE = False        # Flag to indicate a pause between Morse code words\n",
    "    PAUSED = False            # Flag to indicate if processing is paused\n",
    "\n",
    "    # Initialize variables for storing Morse code results\n",
    "    total_morse = \"\"          # Accumulates the entire translated Morse code\n",
    "    morse_word = \"\"           # Stores the Morse code for the current word\n",
    "    morse_char = \"\"           # Stores the Morse code for the current character\n",
    "\n",
    "    while True:\n",
    "        # Capture frame from video stream\n",
    "        frame = vs.read()\n",
    "        # Resize the frame for better processing\n",
    "        frame = imutils.resize(frame, width=450)\n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect faces in the frame\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        for rect in rects:\n",
    "            # Predict facial landmarks for each detected face\n",
    "            shape = predictor(gray, rect)\n",
    "            # Convert facial landmarks to numpy array\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            # Extract left and right eye landmarks\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            # Calculate eye aspect ratio for both eyes\n",
    "            left_eye_ar = eye_aspect_ratio(leftEye)\n",
    "            right_eye_ar = eye_aspect_ratio(rightEye)\n",
    "            eye_ar = (left_eye_ar + right_eye_ar) / 2.0\n",
    "\n",
    "            # Draw contours around the eyes\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "            # Check if the eye aspect ratio is below the threshold (indicating closed eyes)\n",
    "            if eye_ar < constants.EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                BREAK_COUNTER += 1\n",
    "                # If eyes are closed for enough consecutive frames, mark as closed\n",
    "                if COUNTER >= constants.EYE_AR_CONSEC_FRAMES:\n",
    "                    CLOSED_EYES = True\n",
    "                # If not paused, reset Morse character\n",
    "                if not PAUSED:\n",
    "                    morse_char = \"\"\n",
    "                # If eyes have been closed for a long time, break out of the loop\n",
    "                if BREAK_COUNTER >= constants.BREAK_LOOP_FRAMES:\n",
    "                    break\n",
    "            else:\n",
    "                # Reset break counter if eyes are open\n",
    "                if BREAK_COUNTER < constants.BREAK_LOOP_FRAMES:\n",
    "                    BREAK_COUNTER = 0\n",
    "                EYES_OPEN_COUNTER += 1\n",
    "                # Add a dash to Morse code if eyes were closed long enough\n",
    "                if COUNTER >= constants.EYE_AR_CONSEC_FRAMES:\n",
    "                    morse_word += \"-\"\n",
    "                    total_morse += \"-\"\n",
    "                    morse_char += \"-\"\n",
    "                    COUNTER = 0\n",
    "                    CLOSED_EYES = False\n",
    "                    PAUSED = True\n",
    "                    EYES_OPEN_COUNTER = 0\n",
    "                # Add a dot to Morse code if eyes were briefly closed\n",
    "                elif CLOSED_EYES:\n",
    "                    morse_word += \".\"\n",
    "                    total_morse += \".\"\n",
    "                    morse_char += \".\"\n",
    "                    COUNTER = 1\n",
    "                    CLOSED_EYES = False\n",
    "                    PAUSED = True\n",
    "                    EYES_OPEN_COUNTER = 0\n",
    "                # Add a pause between Morse code characters if eyes are open long enough\n",
    "                elif PAUSED and EYES_OPEN_COUNTER >= constants.PAUSE_CONSEC_FRAMES:\n",
    "                    morse_word += \"/\"\n",
    "                    total_morse += \"/\"\n",
    "                    morse_char = \"/\"\n",
    "                    PAUSED = False\n",
    "                    WORD_PAUSE = True\n",
    "                    CLOSED_EYES = False\n",
    "                    EYES_OPEN_COUNTER = 0\n",
    "                    # Write the current Morse code word to the keyboard\n",
    "                    keyboard.write(morse_code.from_morse(morse_word))\n",
    "                    morse_word = \"\"\n",
    "                # Add a longer pause between words if eyes are open long enough\n",
    "                elif WORD_PAUSE and EYES_OPEN_COUNTER >= constants.WORD_PAUSE_CONSEC_FRAMES:\n",
    "                    total_morse += \"Â¦/\"\n",
    "                    morse_char = \"\"\n",
    "                    WORD_PAUSE = False\n",
    "                    CLOSED_EYES = False\n",
    "                    EYES_OPEN_COUNTER = 0\n",
    "                    # Write a space to the keyboard to indicate a word separation\n",
    "                    keyboard.write(morse_code.from_morse(\"Â¦/\"))\n",
    "\n",
    "            # Display the eye aspect ratio and Morse character on the frame\n",
    "            cv2.putText(frame, \"EAR: {:.2f}\".format(eye_ar), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"{}\".format(morse_char), (100, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 2)\n",
    "\n",
    "            # Print current Morse code word to the console\n",
    "            print(\"\\033[K\", \"morse_word: {}\".format(morse_word), end=\"\\r\")\n",
    "\n",
    "        # Show the frame in a window\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        # Check for user input to exit the loop\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Break the loop if the user presses the \"]\" key or if the break counter exceeds the threshold\n",
    "        if key == ord(\"]\") or BREAK_COUNTER >= constants.BREAK_LOOP_FRAMES:\n",
    "            keyboard.write(morse_code.from_morse(morse_word))\n",
    "            break\n",
    "\n",
    "    # Return the total Morse code detected\n",
    "    return total_morse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(vs):\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(total_morse):\n",
    "    print(\"Morse Code: \", total_morse.replace(\"Â¦\", \" \"))\n",
    "    print(\"Translated: \", morse_code.from_morse(total_morse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    arg_par = argparse.ArgumentParser()\n",
    "    arg_par.add_argument(\"-p\", \"--shape-predictor\", required=True, help=\"path to facial landmark predictor\")\n",
    "    args = vars(arg_par.parse_args())\n",
    "\n",
    "    (vs, detector, predictor, lStart, lEnd, rStart, rEnd) = setup_detector_video(args)\n",
    "    total_morse = loop_camera(vs, detector, predictor, lStart, lEnd, rStart, rEnd)\n",
    "    cleanup(vs)\n",
    "    print_results(total_morse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -p SHAPE_PREDICTOR\n",
      "ipykernel_launcher.py: error: the following arguments are required: -p/--shape-predictor\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
